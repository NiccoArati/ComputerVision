{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1JzpkMBzadM9250PhvFmP_EjMyU13syrs","timestamp":1731417590485}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Contrastive Loss\n","\n","---\n","In this session, we are going to implement the SimCLR loss function (https://arxiv.org/abs/2002.05709).\n","\n","This follows the InfoNCE loss, i.e., uses two different augmented versions of the same image as positive pair and the other images in the batch as negative samples, and the batch construction of the N-pair-mc loss.\n"],"metadata":{"id":"9WlzRGSguPAX"}},{"cell_type":"code","source":["import os\n","import pandas as pd\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","\n","from torchvision.io import read_image\n","\n","import torchvision\n","import torchvision.models as models\n","import torchvision.transforms as transforms\n","\n","from PIL import Image\n","import time"],"metadata":{"id":"xaJjICcLhd2B","executionInfo":{"status":"ok","timestamp":1734788727860,"user_tz":-60,"elapsed":8431,"user":{"displayName":"Niccolò Arati","userId":"07690613684145163684"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Base version with loops\n","class ContrastiveLossBase(nn.Module):\n","    def __init__(self, temperature=0.07):\n","        super().__init__()\n","        self.temperature = temperature\n","        self.criterion = torch.nn.CrossEntropyLoss()\n","\n","    def forward(self, features, batch_size=64):\n","        ### features = torch.cat((x1,x2), dim=0)\n","        # normalize features to later compute cosine distance/similarity btw them\n","        features = F.normalize(features, dim=1) # (128, 512)\n","        # compute the similarity matrix btw features\n","        # (consider that feature are normalized! so the cosine similarity is dot product)\n","        similarity_matrix = torch.matmul(features, features.T)\n","\n","        start = time.time()\n","        # create the logits tensor where:\n","        #   - in the first position there is the similarity of the positive pair\n","        #   - in the other 2N-1 positions there are the similarity w negatives\n","        # the shape of the tensor need to be 2Nx2N-1, with N is the batch size\n","        logits = torch.zeros(2 * batch_size, 2 *batch_size-1)\n","        for idx, val in enumerate(similarity_matrix):\n","            row = torch.zeros(2 * batch_size-1)\n","            pos_idx = idx + batch_size if idx < batch_size else idx - batch_size # i + N seconda sottomatrice, i - N terza sottomatrice\n","            row[0] = val[pos_idx]\n","            row[1:] = torch.tensor([v for i, v in enumerate(val) if i!=idx and i!=pos_idx])\n","            logits[idx] = row\n","        logits.requires_grad_(requires_grad=True)\n","        print(f\"Logits shape: {logits.shape}\")\n","\n","        logits = logits / self.temperature\n","\n","        # to compute the contrastive loss using the CE loss, we just need to\n","        # specify where is the similarity of the positive pair in the logits tensor\n","        # since we put in the first position we create a gt of all zeros\n","        # N.B.: this is just one of the possible implementations!\n","        gt = torch.zeros(logits.shape[0], dtype=torch.long) # -> indexes of positives\n","        end = time.time()\n","        time_taken = end - start\n","        return time_taken, self.criterion(logits, gt)"],"metadata":{"id":"ABbKJPlwuOb0","executionInfo":{"status":"ok","timestamp":1734789116887,"user_tz":-60,"elapsed":355,"user":{"displayName":"Niccolò Arati","userId":"07690613684145163684"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["# Optimized Version\n","class ContrastiveLoss(nn.Module):\n","    def __init__(self, temperature=0.07):\n","        super().__init__()\n","        self.temperature = temperature\n","        self.criterion = torch.nn.CrossEntropyLoss()\n","\n","    def forward(self, features, batch_size=64):\n","        ### features = torch.cat((x1,x2), dim=0)\n","        # normalize features to later compute cosine distance/similarity btw them\n","        features = F.normalize(features, dim=1) # (128, 512)\n","        # compute the similarity matrix btw features\n","        # (consider that feature are normalized! so the cosine similarity is dot product)\n","\n","        similarity_matrix = torch.matmul(features, features.T)\n","\n","        start = time.time()\n","        labels = torch.cat([torch.arange(features.shape[0]//2) for i in range(2)], dim=0)\n","        labels = (labels.unsqueeze(0) == labels.unsqueeze(1)).float() # diagonale principale identità, e anche nelle diagonali principali delle 4 sottomatrici\n","        mask = torch.eye(labels.shape[0], dtype=torch.bool)\n","        labels = labels[~mask].view(labels.shape[0], -1)\n","        similarity_matrix = similarity_matrix[~mask].view(similarity_matrix.shape[0], -1)\n","\n","        # select and combine multiple positives\n","        positives = similarity_matrix[labels.bool()].view(labels.shape[0], -1)\n","\n","        # select only the negatives\n","        negatives = similarity_matrix[~labels.bool()].view(similarity_matrix.shape[0], -1)\n","\n","        logits = torch.cat((positives, negatives), dim=1)\n","        logits = logits / self.temperature\n","\n","        gt = torch.zeros(logits.shape[0], dtype=torch.long)\n","        end = time.time()\n","        time_taken = end - start\n","        return time_taken, self.criterion(logits, gt)"],"metadata":{"id":"cwlmRQ2FuYFN","executionInfo":{"status":"ok","timestamp":1734789158487,"user_tz":-60,"elapsed":199,"user":{"displayName":"Niccolò Arati","userId":"07690613684145163684"}}},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":["Let's now use the Dataset which creates the two augmented views for each image and the Siamese Network from the past lab session [1](https://colab.research.google.com/drive/1NJwAFbRiD4MdwWf__6P2Lm0xYk_DNdVu?usp=sharing) and [2](https://colab.research.google.com/drive/1AMkh0q8L5nJScx7v6cMWoK336zqOqDY6?usp=sharing) and create a training loop"],"metadata":{"id":"Agvz2chP0Ndg"}},{"cell_type":"code","source":["class SiameseNetSIM(nn.Module):\n","    def __init__(self, backbone):\n","        super().__init__()\n","        self.encoder = backbone\n","\n","    # if pairs are not concatenated before, use this\n","    '''\n","    def forward(self, x1, x2):\n","        images = torch.cat((x1, x2), 0)\n","        features = self.encoder(images)\n","        return features\n","    '''\n","    # if pairs are concatenaed before, use tihs\n","    def forward(self, x):\n","        return self.encoder(x)"],"metadata":{"id":"ePJ9Ypkopo53","executionInfo":{"status":"ok","timestamp":1734788739453,"user_tz":-60,"elapsed":238,"user":{"displayName":"Niccolò Arati","userId":"07690613684145163684"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["class CustomImageDataset(Dataset):\n","    def __init__(self, data, targets, transform=None, target_transform=None):\n","        self.imgs = data\n","        self.targets = targets\n","        self.transform = transform\n","        self.target_transform = target_transform\n","\n","    def __len__(self):\n","        return len(self.targets)\n","\n","    def __getitem__(self, idx):\n","        img_base = self.imgs[idx]\n","        if isinstance(img_base, str):\n","          img_base = read_image(img_base)\n","        label = self.targets[idx]\n","        if self.transform:\n","            img1 = self.transform(img_base)\n","            img2 = self.transform(img_base)\n","        else:\n","            img1 = img_base\n","            img2 = img_base\n","        if self.target_transform:\n","            label = self.target_transform(label)\n","        return img1, img2, label\n","\n","\n","data = torchvision.datasets.CIFAR10(root='./data', train=True, download=True)\n","size = 32\n","s=1\n","color_jitter = transforms.ColorJitter(0.8 * s, 0.8 * s, 0.8 * s, 0.2 * s)\n","transform = transforms.Compose([transforms.ToTensor(),\n","                                  transforms.RandomResizedCrop(size=size),\n","                                  transforms.RandomHorizontalFlip(),\n","                                  transforms.RandomApply([color_jitter], p=0.8),\n","                                  transforms.RandomGrayscale(p=0.2),\n","                                  transforms.GaussianBlur(kernel_size=int(0.1 * size))])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nm2YUFAkqopM","executionInfo":{"status":"ok","timestamp":1734789178210,"user_tz":-60,"elapsed":1432,"user":{"displayName":"Niccolò Arati","userId":"07690613684145163684"}},"outputId":"b266d74d-2c54-4110-ea18-2a7b6a6256a2"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n"]}]},{"cell_type":"code","execution_count":25,"metadata":{"id":"ow1YmaRPt-Py","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734789128668,"user_tz":-60,"elapsed":7175,"user":{"displayName":"Niccolò Arati","userId":"07690613684145163684"}},"outputId":"79a7d84c-aa64-4c93-e7a3-451a3ccd410a"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([64, 3, 32, 32])\n","torch.Size([64, 3, 32, 32])\n","Logits shape: torch.Size([128, 127])\n","Base loss time: 0.047, loss value: 5.199\n","torch.Size([64, 3, 32, 32])\n","torch.Size([64, 3, 32, 32])\n","Logits shape: torch.Size([128, 127])\n","Base loss time: 0.086, loss value: 5.461\n","torch.Size([64, 3, 32, 32])\n","torch.Size([64, 3, 32, 32])\n","Logits shape: torch.Size([128, 127])\n","Base loss time: 0.047, loss value: 6.197\n","torch.Size([64, 3, 32, 32])\n","torch.Size([64, 3, 32, 32])\n","Logits shape: torch.Size([128, 127])\n","Base loss time: 0.051, loss value: 6.390\n"]}],"source":["trainset = CustomImageDataset(data.data, data.targets, transform=transform)\n","dataloader = DataLoader(trainset, batch_size=64, shuffle=True)\n","\n","# you can use a resnet18 as backbone\n","backbone = models.resnet18()\n","\n","#! remember to delete the fc layer (we need just the CNN layers + flatten)\n","backbone.fc = nn.Identity()\n","model = SiameseNetSIM(backbone)\n","optimizer = optim.Adam(model.parameters())\n","criterion = ContrastiveLossBase()\n","\n","for idx, data in enumerate(dataloader):\n","    views1, views2, targets = data\n","    print(views1.shape)\n","    print(views2.shape)\n","\n","    optimizer.zero_grad()\n","    output = model(torch.cat((views1, views2), 0))\n","    time_taken, loss = criterion(output, 64)\n","    loss.backward()\n","    optimizer.step()\n","\n","    print(f\"Base loss time: {time_taken:.3f}, loss value: {loss.item():.3f}\")\n","\n","    if idx == 3:\n","        break"]},{"cell_type":"code","source":["trainset = CustomImageDataset(data.data, data.targets, transform=transform)\n","dataloader = DataLoader(trainset, batch_size=64, shuffle=True)\n","\n","# you can use a resnet18 as backbone\n","backbone = models.resnet18()\n","\n","#! remember to delete the fc layer (we need just the CNN layers + flatten)\n","backbone.fc = nn.Identity()\n","model = SiameseNetSIM(backbone)\n","optimizer = optim.Adam(model.parameters())\n","criterion = ContrastiveLoss()\n","\n","for idx, data in enumerate(dataloader):\n","    views1, views2, targets = data\n","    print(views1.shape)\n","    print(views2.shape)\n","\n","    optimizer.zero_grad()\n","    output = model(torch.cat((views1, views2), 0))\n","    time_taken, loss = criterion(output, 64)\n","    loss.backward()\n","    optimizer.step()\n","\n","    print(f\"Optimized loss time: {time_taken:.3f}, loss value: {loss.item():.3f}\")\n","\n","    if idx == 3:\n","        break"],"metadata":{"id":"gibA9Gr3BLbR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734789186821,"user_tz":-60,"elapsed":7340,"user":{"displayName":"Niccolò Arati","userId":"07690613684145163684"}},"outputId":"5cdded15-9d67-44f3-fc9c-2f6bb1389910"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([64, 3, 32, 32])\n","torch.Size([64, 3, 32, 32])\n","Optimized loss time: 0.004, loss value: 5.581\n","torch.Size([64, 3, 32, 32])\n","torch.Size([64, 3, 32, 32])\n","Optimized loss time: 0.001, loss value: 5.328\n","torch.Size([64, 3, 32, 32])\n","torch.Size([64, 3, 32, 32])\n","Optimized loss time: 0.001, loss value: 5.092\n","torch.Size([64, 3, 32, 32])\n","torch.Size([64, 3, 32, 32])\n","Optimized loss time: 0.002, loss value: 5.390\n"]}]},{"cell_type":"code","source":["# Fare operazioni in place migliora i tempi\n","# prova a trovare altre implementazioni\n","# Per elaborato: presentazione loss, poi schema facendo vedere matrici"],"metadata":{"id":"PAC16QL4i0VO"},"execution_count":null,"outputs":[]}]}
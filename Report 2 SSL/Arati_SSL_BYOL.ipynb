{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1M-qLeeFMXj2BHjYDA20rYCYKtYDhBtoy","timestamp":1731417610286}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Bootstrap Your Own Latent (BYOL)\n","\n","In this session we are going to implement Bootstrap Your Own Latent paper (https://arxiv.org/abs/2006.07733).\n","\n","It uses a MoCo-style training (with asymmetric SiameseNet) but with a L2 loss penalty (it is not a contrastive-base method)."],"metadata":{"id":"IIhoHTwntu1V"}},{"cell_type":"code","source":["import os\n","import pandas as pd\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","\n","from torchvision.io import read_image\n","\n","import torchvision\n","import torchvision.models as models\n","import torchvision.transforms as transforms\n","\n","from PIL import Image\n","import copy"],"metadata":{"id":"NVw6H3IEJVuk","executionInfo":{"status":"ok","timestamp":1734791603809,"user_tz":-60,"elapsed":23909,"user":{"displayName":"Niccolò Arati","userId":"07690613684145163684"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","execution_count":7,"metadata":{"id":"y0Yv5FeDvVm8","executionInfo":{"status":"ok","timestamp":1734791972154,"user_tz":-60,"elapsed":268,"user":{"displayName":"Niccolò Arati","userId":"07690613684145163684"}}},"outputs":[],"source":["# loss fn\n","def loss_fn(x, y):\n","    x = F.normalize(x, dim=-1, p=2)\n","    y = F.normalize(y, dim=-1, p=2)\n","    return 2 - 2 * (x * y).sum(dim=-1) # cosine similarity\n","\n","\n","class EMA():\n","    # exponential moving average\n","    def __init__(self, beta):\n","        super().__init__()\n","        self.beta = beta\n","\n","    def update_average(self, old, new):\n","        if old is None:\n","            return new\n","        return old * self.beta + (1 - self.beta) * new\n","\n","def update_moving_average(ema_updater, ma_model, current_model):\n","    for current_params, ma_params in zip(current_model.parameters(), ma_model.parameters()):\n","        old_weight, up_weight = ma_params.data, current_params.data\n","        ma_params.data = ema_updater.update_average(old_weight, up_weight)\n","\n","# MLP class for projector and predictor\n","\n","def MLP(dim, projection_size, hidden_size=4096, sync_batchnorm=None):\n","    return nn.Sequential(\n","        nn.Linear(dim, hidden_size),\n","        nn.BatchNorm1d(hidden_size),\n","        nn.ReLU(inplace=True),\n","        nn.Linear(hidden_size, projection_size)\n","    )\n","\n","\n","class BYOL(nn.Module):\n","    def __init__(self, backbone, moving_average_decay = 0.99):\n","        super().__init__()\n","\n","        self.target_ema_updater = EMA(moving_average_decay)\n","\n","        self.online_net = backbone\n","        self.online_net.fc = nn.Identity()\n","        self.online_projector = MLP(512, 512, 4096)\n","\n","        self.target_net = None\n","\n","    def _get_target_encoder(self):\n","        if self.target_net is None:\n","            target_net = copy.deepcopy(self.online_net) # copia solo decoder, non il projector\n","            for param in target_net.parameters():\n","                param.requires_grad = False\n","            self.target_net = target_net\n","        else:\n","            target_net = self.target_net\n","        return target_net\n","\n","    def update_moving_average(self):\n","        update_moving_average(self.target_ema_updater, self.target_net, self.online_net)\n","\n","    def forward(self, x1, x2):\n","\n","        images = torch.cat((x1, x2), dim = 0)\n","\n","        online_projections = self.online_projector(self.online_net(images))\n","        online_pred_one, online_pred_two = online_projections.chunk(2, dim = 0) # split tensor\n","\n","        with torch.no_grad():\n","            target_net = self._get_target_encoder()\n","\n","            target_projections = target_net(images) # labels, no SGD -> evito representation collapse\n","            target_projections = target_projections.detach()\n","            target_proj_one, target_proj_two = target_projections.chunk(2, dim = 0) # split tensor\n","\n","        loss_one = loss_fn(online_pred_one, target_proj_two.detach())\n","        loss_two = loss_fn(online_pred_two, target_proj_one.detach())\n","\n","        loss = loss_one + loss_two\n","        return loss.mean()"]},{"cell_type":"markdown","source":["## Exercise 0\n","\n","Study the above code.\n","- Where is the EMA updates?\n","- Why it computes both loss_one and loss_two values?"],"metadata":{"id":"sTq2njrMrvkM"}},{"cell_type":"code","source":["# Answer in report:\n","# sempre per efficienza, si calcolano come se fossero 2 batch di dati (liste \"incrociate\")\n","# Non posso farlo con contrastive loss, calcolerei la stessa cosa"],"metadata":{"id":"DNE8OpJan1xe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Exercise 1\n","\n","Write the training loop for moco-style training as used in BYOL.\n","Use the Dataset which creates the two augmented views for each image and the Siamese Network from the past lab session [1](https://colab.research.google.com/drive/1NJwAFbRiD4MdwWf__6P2Lm0xYk_DNdVu?usp=sharing) and [2](https://colab.research.google.com/drive/1AMkh0q8L5nJScx7v6cMWoK336zqOqDY6?usp=sharing)."],"metadata":{"id":"m3lt3jwGryO-"}},{"cell_type":"code","source":["class SiameseNetASIM(nn.Module):\n","    def __init__(self, backbone, backbone2):\n","        super().__init__()\n","        self.encoder = backbone\n","        self.encoder2 = backbone2\n","\n","    def forward(self, x1, x2):\n","        features = self.encoder(x1)\n","        features2 = self.encoder2(x2)\n","        return torch.cat((features, features2), 0)"],"metadata":{"id":"b7Dm2mXLnvck","executionInfo":{"status":"ok","timestamp":1734791668401,"user_tz":-60,"elapsed":268,"user":{"displayName":"Niccolò Arati","userId":"07690613684145163684"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["class CustomImageDataset(Dataset):\n","    def __init__(self, data, targets, transform=None, target_transform=None):\n","        self.imgs = data\n","        self.targets = targets\n","        self.transform = transform\n","        self.target_transform = target_transform\n","\n","    def __len__(self):\n","        return len(self.targets)\n","\n","    def __getitem__(self, idx):\n","        img_base = self.imgs[idx]\n","        if isinstance(img_base, str):\n","          img_base = read_image(img_base)\n","        label = self.targets[idx]\n","        if self.transform:\n","            img1 = self.transform(img_base)\n","            img2 = self.transform(img_base)\n","        else:\n","            img1 = img_base\n","            img2 = img_base\n","        if self.target_transform:\n","            label = self.target_transform(label)\n","        return img1, img2, label\n","\n","\n","data = torchvision.datasets.CIFAR10(root='./data', train=True, download=True)\n","size = 32\n","s=1\n","color_jitter = transforms.ColorJitter(0.8 * s, 0.8 * s, 0.8 * s, 0.2 * s)\n","transform = transforms.Compose([transforms.ToTensor(),\n","                                  transforms.RandomResizedCrop(size=size),\n","                                  transforms.RandomHorizontalFlip(),\n","                                  transforms.RandomApply([color_jitter], p=0.8),\n","                                  transforms.RandomGrayscale(p=0.2),\n","                                  transforms.GaussianBlur(kernel_size=int(0.1 * size))])"],"metadata":{"id":"LowZ6EqzmCV9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734791985876,"user_tz":-60,"elapsed":1414,"user":{"displayName":"Niccolò Arati","userId":"07690613684145163684"}},"outputId":"0aac3ffd-e8f3-409e-e2ac-1c7b0d911314"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n"]}]},{"cell_type":"code","source":["trainset = CustomImageDataset(data.data, data.targets, transform=transform)\n","dataloader = DataLoader(trainset, batch_size=64, shuffle=True)\n","\n","backbone = models.resnet18()\n","byol = BYOL(backbone)\n","\n","# prendo solo i parametri da aggiornare con SGD, così risparmio tempo e memoria\n","online_net_params = {'params': byol.online_net.parameters()}\n","online_projector_params = {'params': byol.online_projector.parameters()}\n","optimizer = optim.SGD([online_net_params, online_projector_params], lr=0.001, momentum=0.9, weight_decay=1e-04)\n","\n","\n","for idx, data in enumerate(dataloader):\n","    view1, view2, _ = data\n","\n","    optimizer.zero_grad()\n","    iter_loss = byol(view1, view2)\n","    print(f\"Iter {idx} loss: {iter_loss}\")\n","    iter_loss.backward() # gradienti solo dell'online net\n","\n","    optimizer.step() # aggiornamento solo sell'online net\n","    byol.update_moving_average() # aggiorno target net\n","\n","    if idx == 3:\n","        break"],"metadata":{"id":"lJQWtjgZnxNe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734791995527,"user_tz":-60,"elapsed":9657,"user":{"displayName":"Niccolò Arati","userId":"07690613684145163684"}},"outputId":"9b27a914-a322-43a8-e93a-ebd32213c6c7"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Iter 0 loss: 4.021104335784912\n","Iter 1 loss: 3.9903438091278076\n","Iter 2 loss: 3.8605329990386963\n","Iter 3 loss: 3.7224299907684326\n"]}]}]}